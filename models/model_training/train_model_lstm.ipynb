{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540e4889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, GlobalAveragePooling1D, Concatenate, LayerNormalization, MultiHeadAttention, Masking\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "from sklearn.utils import class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2234dbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e842a0d7",
   "metadata": {},
   "source": [
    "![الوصف هنا](image/pipe.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7ef5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/shatha/projects_unix/sign_model/data_labels/.csv')\n",
    "test = pd.read_csv('/home/shatha/projects_unix/sign_model/data_labels/.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ed5d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525034a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd513964",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_feature_cols = ['signerID', 'sign', 'NoFrames', 'SignID', 'Sign-Arabic', 'Sign-English']\n",
    "feature_cols = [col for col in train.columns if col not in non_feature_cols]\n",
    "\n",
    "\n",
    "feature_cols = [\n",
    "    col for col in train.columns\n",
    "    if col not in non_feature_cols and any(k in col for k in feature_cols) and col.endswith(('_X', '_Y'))\n",
    "]\n",
    "\n",
    "feature_cols = sorted(feature_cols)\n",
    "print(f\"عدد الأعمدة المختارة: {len(feature_cols)}\")  # لازم يطلع 106\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00926079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "def build_input_matrix(df, num_frames, feature_cols):\n",
    "    num_features = len(feature_cols)\n",
    "    X = np.zeros((len(df), num_frames, num_features), dtype=np.float32)\n",
    "\n",
    "    for i, col in enumerate(feature_cols):\n",
    "        for j in range(len(df)):\n",
    "            try:\n",
    "                raw = ast.literal_eval(df[col].iloc[j])\n",
    "                length = len(raw)\n",
    "                X[j, :min(length, num_frames), i] = raw[:num_frames]\n",
    "            except Exception as e:\n",
    "                print(f\" خطأ في العمود {col} والسطر {j}: {e}\")\n",
    "                X[j, :, i] = 0.0\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec090a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = build_input_matrix(train, num_frames=30, feature_cols=feature_cols)\n",
    "X_test = build_input_matrix(test, num_frames=30, feature_cols=feature_cols)\n",
    "\n",
    "print(\" X_train shape:\", X_train.shape)\n",
    "print(\" X_test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7a2ca7",
   "metadata": {},
   "source": [
    "4-ترميز التسميات (Label Encoding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844aded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train['Sign-Arabic'])\n",
    "y_test = le.transform(test['Sign-Arabic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b3180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_video_sequences(X, scaler=None):\n",
    "    reshaped = X.reshape(-1, X.shape[-1])  # (num_samples * 30, 108)\n",
    "    \n",
    "    valid_rows = ~np.all(reshaped == 0, axis=1)\n",
    "    valid_data = reshaped[valid_rows]\n",
    "\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(valid_data)\n",
    "    \n",
    "    scaled_data = reshaped.copy()\n",
    "    scaled_data[valid_rows] = scaler.transform(valid_data)\n",
    "    \n",
    "    return scaled_data.reshape(X.shape), scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99231ea7",
   "metadata": {},
   "source": [
    "5-تسوية البيانات (Scaling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13201ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, scaler = scale_video_sequences(X_train)\n",
    "X_test, _ = scale_video_sequences(X_test, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494a4f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train.npy', X_train)\n",
    "joblib.dump(scaler, '/home/shatha/projects_unix/sign_model/hybird_models/hybird_v3_toptransfprm/scaler.joblib')\n",
    "joblib.dump(le, '/home/shatha/projects_unix/sign_model/hybird_models/hybird_v3_toptransfprm/label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b847ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" الأبعاد النهائية:\")\n",
    "print(f\"X_train: {X_train.shape} (عينات, إطارات, سمات)\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape} (تصنيفات)\")\n",
    "print(f\"عدد الفئات: {len(le.classes_)}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(*np.unique(y_train, return_counts=True))\n",
    "plt.title(\"توزيع الفئات في y_train\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb60127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for u, c in zip(unique, counts):\n",
    "    print(f\"{le.inverse_transform([u])[0]}: {c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7b3759",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i = 50  # أي رقم عينة\n",
    "sample = X_test[i]\n",
    "print(\"قبل التقييس:\", sample.shape, sample.min(), sample.max())\n",
    "print(np.isnan(sample).any())  # هل فيه NaN؟\n",
    "\n",
    "scaled = scaler.transform(sample.reshape(-1, 108)).reshape(1, 30, 108)\n",
    "print(\"بعد التقييس:\", scaled.shape, scaled.min(), scaled.max())\n",
    "print(np.isnan(scaled).any())  # هل فيه NaN؟\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a55677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class_counts = Counter(y_train)\n",
    "sorted_counts = dict(sorted(class_counts.items()))\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(sorted_counts.keys(), sorted_counts.values())\n",
    "plt.title(\"توزيع الفئات في y_train\")\n",
    "plt.xlabel(\"الفئة\")\n",
    "plt.ylabel(\"عدد العينات\")\n",
    "plt.show()\n",
    "\n",
    "counts = np.array(list(class_counts.values()))\n",
    "max_count = counts.max()\n",
    "min_count = counts.min()\n",
    "print(f\"أكبر فئة: {max_count} | أصغر فئة: {min_count}\")\n",
    "print(f\"النسبة بين أكبر وأصغر فئة: {round(max_count / min_count, 2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85826f9",
   "metadata": {},
   "source": [
    "soft class weight معالجة عدم توازن بين الفئات"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317c28c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "raw_class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "attenuation_factor = 0.3  \n",
    "soft_weights = raw_class_weights ** attenuation_factor\n",
    "\n",
    "class_weights = dict(enumerate(soft_weights))\n",
    "\n",
    "for i, w in class_weights.items():\n",
    "    print(f\"الفئة {i}: الوزن = {round(w, 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a3c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def transformer_encoder(inputs, head_size=96, num_heads=4, ff_dim=4, dropout=0.1):\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = MultiHeadAttention(\n",
    "        key_dim=head_size // num_heads,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout\n",
    "    )(x, x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    x = LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = Dense(ff_dim, activation=\"gelu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(inputs.shape[-1])(x)\n",
    "    return x + res\n",
    "\n",
    "def build_hybrid_model(input_shape, num_classes, mask_value=-10.0):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Masking Layer\n",
    "    masked = Masking(mask_value=mask_value)(inputs)\n",
    "    \n",
    "    # Transformer Branch\n",
    "    x_trans = transformer_encoder(masked, head_size=96)\n",
    "    x_trans = transformer_encoder(x_trans, head_size=48)\n",
    "    x_trans = GlobalAveragePooling1D()(x_trans)\n",
    "    \n",
    "    # LSTM Branch\n",
    "    x_lstm = LSTM(64, return_sequences=True)(masked)\n",
    "    x_lstm = Dropout(0.3)(x_lstm)\n",
    "    x_lstm = LSTM(32)(x_lstm)\n",
    "    \n",
    "    x = Concatenate()([x_trans, x_lstm])\n",
    "    x = Dense(128, activation='gelu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # (30, 108)\n",
    "num_classes = len(np.unique(y_train))\n",
    "model = build_hybrid_model(input_shape, num_classes)\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weights\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"\\n accuracy on test set :accuracy\")\n",
    "print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0300757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(f\"\\n accuracy on test set :accuracy\")\n",
    "print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "# الدقة\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# الخسارة\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf4c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"hybrid_model_final_108.keras\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df047c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# تحميل المقيس والمحول\n",
    "scaler = joblib.load(\"/home/shatha/projects_unix/sign_model/hybird_models/hybird_v2_toptransfprm/scaler.joblib\")\n",
    "label_encoder = joblib.load(\"/home/shatha/projects_unix/sign_model/hybird_models/hybird_v2_toptransfprm/label_encoder.joblib\")\n",
    "sample = X_train[9000].reshape(1, 30, 108)\n",
    "pred = model.predict(sample)\n",
    "pred_label = label_encoder.inverse_transform([np.argmax(pred)])\n",
    "true_label = label_encoder.inverse_transform([y_train[9000]])\n",
    "\n",
    "print(\" التوقع:\", pred_label[0])\n",
    "print(\" الحقيقة:\", true_label[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32ad510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, LSTM, Dense, Dropout, \n",
    "    MultiHeadAttention, LayerNormalization, \n",
    "    GlobalAveragePooling1D, Concatenate, Masking\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "def transformer_encoder(inputs, head_size=128, num_heads=4, ff_dim=64, dropout=0.2):\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = MultiHeadAttention(\n",
    "        key_dim=head_size // num_heads,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout\n",
    "    )(x, x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    x = LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = Dense(ff_dim, activation=\"gelu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(inputs.shape[-1])(x)\n",
    "    return x + res\n",
    "\n",
    "\n",
    "def build_hybrid_model_v2(input_shape, num_classes, mask_value=-10.0):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    masked = Masking(mask_value=mask_value)(inputs)\n",
    "\n",
    "    # Transformer Branch\n",
    "    x_trans = transformer_encoder(masked)\n",
    "    x_trans = transformer_encoder(x_trans, head_size=96)\n",
    "    x_trans = transformer_encoder(x_trans, head_size=64)\n",
    "    x_trans = GlobalAveragePooling1D()(x_trans)\n",
    "\n",
    "    # LSTM Branch\n",
    "    x_lstm = LSTM(128, return_sequences=True)(masked)\n",
    "    x_lstm = Dropout(0.4)(x_lstm)\n",
    "    x_lstm = LSTM(64)(x_lstm)\n",
    "\n",
    "    # Concatenation & Output\n",
    "    x = Concatenate()([x_trans, x_lstm])\n",
    "    x = Dense(128, activation='gelu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "\n",
    "# Compilation and training section\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # (30, 108)\n",
    "num_classes = len(np.unique(y_train))\n",
    "model_v2 = build_hybrid_model_v2(input_shape, num_classes)\n",
    "\n",
    "model_v2.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(patience=2, factor=0.5, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "history_v2 = model_v2.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "loss_v2, accuracy_v2 = model_v2.evaluate(X_test, y_test)\n",
    "print(f\"\\n accuracy on test set :accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf212768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"\\n accuracy on test set : {accuracy_v2}\")\n",
    "print(f\"Loss: {loss_v2:.4f}, Accuracy: {accuracy_v2:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# الدقة\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_v2.history['accuracy'], label='Train')\n",
    "plt.plot(history_v2.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# الخسارة\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_v2.history['loss'], label='Train')\n",
    "plt.plot(history_v2.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f123bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v2.save(\"/home/shatha/projects_unix/sign_model/hybird_models/hybird_v2_toptransfprm/hybrid_model_v100.keras\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa06c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "scaler = joblib.load(\"/home/shatha/projects_unix/sign_model/hybird_models/hybird_v2_toptransfprm/scaler.joblib\")\n",
    "label_encoder = joblib.load(\"/home/shatha/projects_unix/sign_model/hybird_models/hybird_v2_toptransfprm/label_encoder.joblib\")\n",
    "sample = X_test[2900].reshape(1, 30, 108)\n",
    "pred = model_v2.predict(sample)\n",
    "pred_label = label_encoder.inverse_transform([np.argmax(pred)])\n",
    "true_label = label_encoder.inverse_transform([y_test[2900]])\n",
    "\n",
    "print(\" التوقع:\", pred_label[0])\n",
    "print(\" الحقيقة:\", true_label[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f04875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(10):\n",
    "    sample = X_test[i].reshape(1, 30, 108)\n",
    "    pred = model_v2.predict(sample)\n",
    "    print(f\"{i}: التوقع:\", label_encoder.inverse_transform([np.argmax(pred)]),\n",
    "          \"| الحقيقة:\", label_encoder.inverse_transform([y_test[i]]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63379f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "label_encoder = joblib.load(\"label_encoder.joblib\")\n",
    "\n",
    "print(label_encoder.classes_)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
